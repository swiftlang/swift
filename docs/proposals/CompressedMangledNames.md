
Motivation
----------

We care deeply about the size of binaries that are generated by the Swift
compiler and make an effort to optimize and shrink the generated binaries. One
of the problems that we have today is that swift symbols are mangled into
extremely long strings. This is especially a problem for libraries, and almost
half of the size of libswiftCore.dylib (the swift runtime library on x86_64 OSX)
is string tables. On MacOSX you can use the command ’size -m file.dylib’ to read
the size of the string table. C++ also suffers from the problem of long names,
but since we control the Swift ABI we can do better than C++.

Here are two names from the Swift libraries:

 __TIF14StdlibUnittest13checkSequenceu0_Rxs14CollectionType_s12SequenceTypeWx9Generator7Element_zW_9GeneratorS3__rFTxq_KT_SS9showFrameSb10stackTraceVS_14SourceLocStack4fileSS4lineSu16resiliencyChecksVS_32CollectionMisuseResiliencyChecks9sameValueFTWxS2_S3__WxS2_S3___Sb_T_A6_

 __TTSg5VSS13CharacterViewS_s14CollectionTypes_GVs17IndexingGeneratorS__GS1_S__s13GeneratorTypes_VS_5IndexS3_s16ForwardIndexTypes_SiSis18_SignedIntegerTypes_SiSis33_BuiltinIntegerLiteralConvertibles_Vs20_DisabledRangeIndex__S_S_s9IndexablesS_s12SequenceTypes_GS1_S__GS1_S__S2_s_Vs9Character_S3_S3_S4_s_SiSiS5_s_SiSiS6_s_S7__S__S10__S10____TFFSS12replaceRangeuRxs14CollectionTypeWx9Generator7Element_zVs9CharacterrFTGVs5RangeVVSS13CharacterView5Index_4withx_T_U_FRS4_T_

Swift is a systems programming language, and we need to prepare to a future
where the whole operating system is developed in Swift. This means that one day
our phones will have hundreds of shared libraries (written in swift) loaded at
the same time. Thousands of shared libraries will be saved on disk, and updated
every time you upgrade the OS and apps. The string table (linkedit section in
Mach-O) is loaded into memory (as shared copy-on-write). In a world where every
single process uses multiple swift libraries reducing the size of this section
is very beneficial for memory usage, load time, disk usage, etc..

On-disk and over-the-air compression can improve things, but these techniques
are insufficient because generic compression is not as effective as domain
specific compression, and they do not address the problem of in-memory tables.


Character Set
-------------
The decision on a character set to be used by the compression scheme is
independent of the algorithms that are used for compression. The more characters
that we can use the more efficient the encoding would be. The Base64 encoding
scheme uses 64 characters and has a 75% efficiency compared to unrestricted
8-bit ascii. Base64 uses 6 bits to encode 8 bits of ascii.

The current implementation uses the character set A-Z, a-z, 0-9 and "_", which
are the legal identifier characters in C.  We need to use only printable
characters if we want tools such as nm to be able to work well. It is possible
to extend the character set to more printable characters but this will make SIL
(that uses these names freely) less usable. For example, names should probable
not contain the character <space>, but <equal sign> is probably okay.

Symbol Compression
------------------

This section describes the Swift symbol compression. In Swift we compress each
symbol individually as part of the mangling phase. The compression phase has two
steps:

1. Dictionary based compression (similar to Lempel-Ziv)
2. Variable length compression (Huffman Coding)

The swift Mangler and Demangler are responsible for compressing and
decompressing the symbols, and this process is transparent to the debugger. The
nm command line tool prints the compressed name, and swift-demangle is
responsible for decompressing and demangling the name properly.

Together, the Dictionary based compression and the Variable length compression
are able to compress the size of the string section down to 50% (half of the
original size).

Dictionary-based compression
----------------------------

This section describes the dictionary based compression. This compression phase
reduces the string table section by about 40%. Unlike Lempel-Ziv, the
dictionary-based compression algorithm that we use here can't make use of string
repetitions to compress the string because the input strings are too short. The
obvious alternative is to use "prior knowledge".  We know what are the common
sub-strings that are used in Swift names.  Some of the most common substrings in
Swift mangled names are:

 "S_S_S_S", "ollectio", "Type", "Index", "erator", "7Element", and "able".

We can use this prior knowledge to compress our mangling!

In our compression scheme we compress this string:

__TTSg5VSS13CharacterView

Into a string that contains references to some global table that is available to the compressor and decompressor.

__TTSg5<reference to word #67>13<reference to word #43>View

Commonly used strings are encoded as references to global tables. The reference
needs to be encoded as part of the name.  We need to have some escape character
and use that character to encode the reference. In our encoding scheme we have two
escape characters.

The first escape character records an index using a single character. This allows us to encode
the top 63 frequent substrings in our dictionary using two characters (escape + index).

The second escape character encodes a two-character reference that can access 63 x 63 entries in the table.
Less common substrings can be encoded using this three character sequence (escape + index0 + index1).

One interesting bit of information is that the character ‘Y’ is only used 4
times in the entire standard library! The letter J, and a few other letters are
also not used very frequently. We use Y and J as escape characters.

The dictionary-based encoding uses the following rules:

1. We use two escape characters that are not frequently used in names (Y and Z).
These characters are escape character and cannot be used as part of the text
without escaping. ‘Y’ is encoded as ‘YY’, and ‘Z’ would be encoded as ‘YZ’.

2. The most commonly used sub-strings (calculated as length of substring times
number of occurrences) is encoded with a single escape character and a
single index character. The table of highly repetitive substrings can only
contain 61 entries (a-zA-Z0-9_, minus two escape characters).

A reference to the very frequent substrings is encoded as "Yx", where x is the
character that is translated into a numeric index. This is two chars per
substring.

3. The less frequently used substrings are encoded as three-character sequence.
"Zxx", where xx is the numeric index in the large table (that can hold 61*61
substrings).

It is obvious how to reverse this compression using the same string table used
to compress the names.

With this encoding scheme the name
"__TwxxV14StdlibUnittest24MinimalForwardCollection" becomes
"__TwxxJ1QYrt24J6wJ5KY9on" and the name "__TMPVs15ContiguousArray" becomes
"__TMPJOSJ6lJ8G".

Notice that the "_T" prefix is kept and should not be compressed because it
differentiates between swift symbols and non-swift symbols.

These are two related works on dictionary-based compression:

"Text compression using a 4 bit coding scheme" by J Pike.
"A universal algorithm for sequential data compression (1977)" by Jacob Ziv , Abraham Lempel

Variable Length encoding
------------------------

The variable length encoding that we use is pretty standard. We use Huffman
encoding to encode frequently used characters with few bits. One interesting
aspect of the problem is that we use a character set that is not a power of two.
To encode a bit stream in a character set that is now a power of two we need to
represent the whole name as a big number and perform the operation of div-modulo
for each character we encode, where the div-modulo value is the number of
characters we use to encode the string.

Strings are encoded into numbers in reverse (end to start) to make the
decompression faster by allowing strings to be appended and not prepended.

Implementation
--------------

This section describes the implementation of the symbol compression. Both the
dictionary-based compression and the variable length compression are implemented
in a similar way. An external program is used to scan lots of data that
represents the kind of strings that are likely to be common, and generate header
files that contain information that is used by the compression routines.

The dictionary-based compression generates an H file that contains information
about the escape characters used, the list of words in the codebook (this is the
list of substrings), a list of lengths for each substrings (to accelerate length
calculations).

Our codebook contains about 3000 entries. In order to compress a word we need to
search the whole codebook, for every character in the string. This is slow
inefficient. Instead, the external program is generating a C program that
implements a search in a Trie-like data structure. The auto-generate search
routine exposes an API that returns the index of the matched word given a string
(the original uncompressed symbol) and length until the end of the string.

The Huffman coding uses a similar technique. An external program auto-generates
routines that encode a sequence of strings into a number, or extract a number from
a sequence of strings.

The external programs CBCGen.py and HuffGen.py generate the header files
HuffTables.h and CBC.h.

Generating the compiler header files
------------------------------------

This section describes how to generate the compression tables using a training
set and create the header files (that are currently checked in as part of the
compiler). We generate the compression codebook and the Huffman tables using
data that we think represent the kind of symbol names people use in Swift. It is
important to select training data that is representitive or else the compression
will be less effective.

Step1: Generate a list of mangled names from swift dylibs. This is done using
the "nm" command: "nm libSwiftCode.dylib > names.txt". Next, remove the prefix
that nm is adding (stuff like "U", "T" and "t" and addresses of symbols in the
dylib) and keep one name per line.

Once we enable compression in our manglers you will need to decompress these
names using the utility swift-compress:
"cat compressed_names.txt | swift-compress -decompress > names.txt"

Step2: Run "CBCGen.py file1.txt file2.txt file3.txt > CBC.h"
This will create the CBC header file.

Step3: Recompile swift-compress and use it to compress names without applying
huffman encoding: "cat names.txt | swift-compress -cbc-only > names.txt.cbc"
This will create a file with names that are only compressed with the CBC
encoder, which is the input of our huffman encoder.

Step4: Run HuffGen on the cbc-compressed file to generate the huffman encoding
tables: "./HuffGen.py names.txt.cbc > HuffTables.h"

Error handling
--------------

The compression routines only handle characters that are in the list of valid
characters.  It is possible to compress every string that uses the valid
character set. However, now all incoming strings are legal. For example the
string "Y" is illegal because 'Y' is an escape character and the decoded expects
another character to follow the escape character.

There are a few users that will use the compression routines: The
mangler/demangler/remangler (in the compiler and debugger), the migration tool,
the unittests, etc. The current error handling strategy is to have asserts in
the compiler (in release builds).  In addition to asserts the compiler handles
the decoding of malformed strings by returning an empty string. This is not
ideal and the compression routines should return a boolean flag that says if the
decompression succeeded.

Migration plan
--------------

Once we finalize the encoding scheme we need to update many places in the compiler. This includes testcases
and places in the compiler where we've hard coded names of functions.
The swift-compress utility can be used to compress and decompress mangled names that appear in text..
Just like swift-demangle this utility can replace strings and preserve the text around the mangled name.
This tool can help us in upgrading test files.

