// RUN: %target-swift-frontend -I %S/Inputs/abi %s -emit-ir -enable-union-import | FileCheck %s

// REQUIRES: CPU=x86_64

sil_stage canonical
import c_layout
import Builtin

// CHECK: %VSC11BitfieldOne = type <{ %VSs6UInt32, %VSC6Nested, [1 x i8], [4 x i8], [4 x i8], %Sf, [1 x i8], [7 x i8], %VSs6UInt64, %VSs6UInt32 }>
// CHECK: %VSC6Nested = type <{ %Sf, [3 x i8] }>

// CHECK: %VSC26BitfieldSeparatorReference = type [[BITFIELD_SEP_TYPE:<{ %VSs5UInt8, \[3 x i8\], %VSs5UInt8 }>]]
// CHECK: %VSC25BitfieldSeparatorSameName = type [[BITFIELD_SEP_TYPE]]
// CHECK: %VSC36BitfieldSeparatorDifferentNameStruct = type [[BITFIELD_SEP_TYPE]]
// CHECK: %VSC21BitfieldSeparatorAnon = type [[BITFIELD_SEP_TYPE]]

sil public_external @createBitfieldOne : $@thin @cc(cdecl) () -> BitfieldOne
sil public_external @consumeBitfieldOne : $@thin @cc(cdecl) (BitfieldOne) -> ()

sil @test0 : $() -> () {
bb0:
  %0 = function_ref @createBitfieldOne : $@thin @cc(cdecl) () -> BitfieldOne
  %1 = apply %0() : $@thin @cc(cdecl) () -> BitfieldOne
  %2 = function_ref @consumeBitfieldOne : $@thin @cc(cdecl) (BitfieldOne) -> ()
  apply %2(%1) : $@thin @cc(cdecl) (BitfieldOne) -> ()
  %r = tuple ()
  return %r : $()
}
// CHECK: define void @test0()
// CHECK:   [[RESULT:%.*]] = alloca %VSC11BitfieldOne, align 8
// CHECK:   [[ARG:%.*]] = alloca %VSC11BitfieldOne, align 8
//   Make the first call and pull all the values out of the indirect result.
// CHECK:   call void @createBitfieldOne(%VSC11BitfieldOne* noalias sret [[RESULT]])
// CHECK:   [[ADDR_A:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[RESULT]], i32 0, i32 0
// CHECK:   [[ADDR_A_V:%.*]] = getelementptr inbounds %VSs6UInt32, %VSs6UInt32* [[ADDR_A]], i32 0, i32 0
// CHECK:   [[A:%.*]] = load i32, i32* [[ADDR_A_V]], align 8
// CHECK:   [[ADDR_B:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[RESULT]], i32 0, i32 1
// CHECK:   [[ADDR_B_X:%.*]] = getelementptr inbounds %VSC6Nested, %VSC6Nested* [[ADDR_B]], i32 0, i32 0
// CHECK:   [[ADDR_B_X_V:%.*]] = getelementptr inbounds %Sf, %Sf* [[ADDR_B_X]], i32 0, i32 0
// CHECK:   [[B_X:%.*]] = load float, float* [[ADDR_B_X_V]], align 4
// CHECK:   [[ADDR_B_YZ:%.*]] = getelementptr inbounds %VSC6Nested, %VSC6Nested* [[ADDR_B]], i32 0, i32 1
// CHECK:   [[ADDR_B_YZ_1:%.*]] = bitcast [3 x i8]* [[ADDR_B_YZ]] to i24*
// CHECK:   [[B_YZ:%.*]] = load i24, i24* [[ADDR_B_YZ_1]], align 4
// CHECK:   [[ADDR_CDE:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[RESULT]], i32 0, i32 3
// CHECK:   [[ADDR_CDE_1:%.*]] = bitcast [4 x i8]* [[ADDR_CDE]] to i32*
// CHECK:   [[CDE:%.*]] = load i32, i32* [[ADDR_CDE_1]], align 4
// CHECK:   [[ADDR_FGH:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[RESULT]], i32 0, i32 4
// CHECK:   [[ADDR_FGH_1:%.*]] = bitcast [4 x i8]* [[ADDR_FGH]] to i32*
// CHECK:   [[FGH:%.*]] = load i32, i32* [[ADDR_FGH_1]], align 8
// CHECK:   [[ADDR_I:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[RESULT]], i32 0, i32 5
// CHECK:   [[ADDR_I_V:%.*]] = getelementptr inbounds %Sf, %Sf* [[ADDR_I]], i32 0, i32 0
// CHECK:   [[I:%.*]] = load float, float* [[ADDR_I_V]], align 4
// CHECK:   [[ADDR_JK:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[RESULT]], i32 0, i32 6
// CHECK:   [[ADDR_JK_1:%.*]] = bitcast [1 x i8]* [[ADDR_JK]] to i8*
// CHECK:   [[JK:%.*]] = load i8, i8* [[ADDR_JK_1]], align 8
// CHECK:   [[ADDR_L:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[RESULT]], i32 0, i32 8
// CHECK:   [[ADDR_L_V:%.*]] = getelementptr inbounds %VSs6UInt64, %VSs6UInt64* [[ADDR_L]], i32 0, i32 0
// CHECK:   [[L:%.*]] = load i64, i64* [[ADDR_L_V]], align 8
// CHECK:   [[ADDR_M:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[RESULT]], i32 0, i32 9
// CHECK:   [[ADDR_M_V:%.*]] = getelementptr inbounds %VSs6UInt32, %VSs6UInt32* [[ADDR_M]], i32 0, i32 0
// CHECK:   [[M:%.*]] = load i32, i32* [[ADDR_M_V]], align 8
//   Put all of the values into the indirect argument and make the second call.
// CHECK:   [[ADDR_A:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[ARG]], i32 0, i32 0
// CHECK:   [[ADDR_A_V:%.*]] = getelementptr inbounds %VSs6UInt32, %VSs6UInt32* [[ADDR_A]], i32 0, i32 0
// CHECK:   store i32 [[A]], i32* [[ADDR_A_V]], align 8
// CHECK:   [[ADDR_B:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[ARG]], i32 0, i32 1
// CHECK:   [[ADDR_B_X:%.*]] = getelementptr inbounds %VSC6Nested, %VSC6Nested* [[ADDR_B]], i32 0, i32 0
// CHECK:   [[ADDR_B_X_V:%.*]] = getelementptr inbounds %Sf, %Sf* [[ADDR_B_X]], i32 0, i32 0
// CHECK:   store float [[B_X]], float* [[ADDR_B_X_V]], align 4
// CHECK:   [[ADDR_B_YZ:%.*]] = getelementptr inbounds %VSC6Nested, %VSC6Nested* [[ADDR_B]], i32 0, i32 1
// CHECK:   [[ADDR_B_YZ_1:%.*]] = bitcast [3 x i8]* [[ADDR_B_YZ]] to i24*
// CHECK:   store i24 [[B_YZ]], i24* [[ADDR_B_YZ_1]], align 4
// CHECK:   [[ADDR_CDE:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[ARG]], i32 0, i32 3
// CHECK:   [[ADDR_CDE_1:%.*]] = bitcast [4 x i8]* [[ADDR_CDE]] to i32*
// CHECK:   store i32 [[CDE]], i32* [[ADDR_CDE_1]], align 4
// CHECK:   [[ADDR_FGH:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[ARG]], i32 0, i32 4
// CHECK:   [[ADDR_FGH_1:%.*]] = bitcast [4 x i8]* [[ADDR_FGH]] to i32*
// CHECK:   store i32 [[FGH]], i32* [[ADDR_FGH_1]], align 8
// CHECK:   [[ADDR_I:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[ARG]], i32 0, i32 5
// CHECK:   [[ADDR_I_V:%.*]] = getelementptr inbounds %Sf, %Sf* [[ADDR_I]], i32 0, i32 0
// CHECK:   store float [[I]], float* [[ADDR_I_V]], align 4
// CHECK:   [[ADDR_JK:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[ARG]], i32 0, i32 6
// CHECK:   [[ADDR_JK_1:%.*]] = bitcast [1 x i8]* [[ADDR_JK]] to i8*
// CHECK:   store i8 [[JK]], i8* [[ADDR_JK_1]], align 8
// CHECK:   [[ADDR_L:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[ARG]], i32 0, i32 8
// CHECK:   [[ADDR_L_V:%.*]] = getelementptr inbounds %VSs6UInt64, %VSs6UInt64* [[ADDR_L]], i32 0, i32 0
// CHECK:   store i64 [[L]], i64* [[ADDR_L_V]], align 8
// CHECK:   [[ADDR_M:%.*]] = getelementptr inbounds %VSC11BitfieldOne, %VSC11BitfieldOne* [[ARG]], i32 0, i32 9
// CHECK:   [[ADDR_M_V:%.*]] = getelementptr inbounds %VSs6UInt32, %VSs6UInt32* [[ADDR_M]], i32 0, i32 0
// CHECK:   store i32 [[M]], i32* [[ADDR_M_V]], align 8
// CHECK:   call void @consumeBitfieldOne(%VSC11BitfieldOne* byval align 8 [[ARG]])
// CHECK:   ret void


sil public_external @testBitfields : $@thin () -> (BitfieldSeparatorReference, BitfieldSeparatorSameName, BitfieldSeparatorDifferentNameStruct, BitfieldSeparatorAnon)

sil @testTypedefs : $() -> () {
bb0:
  %0 = function_ref @testBitfields : $@thin () -> (BitfieldSeparatorReference, BitfieldSeparatorSameName, BitfieldSeparatorDifferentNameStruct, BitfieldSeparatorAnon)
  %1 = apply %0() : $@thin () -> (BitfieldSeparatorReference, BitfieldSeparatorSameName, BitfieldSeparatorDifferentNameStruct, BitfieldSeparatorAnon)
  %r = tuple ()
  return %r : $()
}

sil public_external @createSIMDStruct : $@thin @cc(cdecl) () -> SIMDStruct
sil public_external @consumeSIMDStruct : $@thin @cc(cdecl) SIMDStruct -> ()

// CHECK-LABEL: define void @testSIMDStruct()
// CHECK:         alloca <2 x double>, align 16
// CHECK:         alloca i128, align 16
sil @testSIMDStruct : $() -> () {
bb0:
  %f = function_ref @createSIMDStruct : $@thin @cc(cdecl) () -> SIMDStruct
  %x = apply %f() : $@thin @cc(cdecl) () -> SIMDStruct
  %g = function_ref @consumeSIMDStruct : $@thin @cc(cdecl) SIMDStruct -> ()
  %z = apply %g(%x) : $@thin @cc(cdecl) SIMDStruct -> ()
  return undef : $()
}

sil @testRecursive : $@thin () -> Builtin.Word {
bb0:
  %m = metatype $@thin HasRecursivePointers.Type
  %s = builtin "sizeof"<HasRecursivePointers>(%m : $@thin HasRecursivePointers.Type) : $Builtin.Word
  return %s : $Builtin.Word
}
